{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "# coding : utf-8\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.misc import imsave\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessedDataset(chainer.dataset.DatasetMixin):\n",
    "    def __init__(self, base_image_dataset):\n",
    "        self.base = base_image_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def get_example(self, i):\n",
    "        color_image = self.base[i]\n",
    "        gray_image = np.ndarray((32, 32), dtype=np.float32)\n",
    "        for ch in range(3):\n",
    "            # 輝度を計算し、モノクロ画像を作成\n",
    "            gray_image = (\n",
    "                0.298912*color_image[0]\n",
    "                + 0.586611*color_image[1]\n",
    "                + 0.114478*color_image[2]\n",
    "            )\n",
    "        return gray_image, color_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIC_FC(chainer.Chain):\n",
    "    def __init__(self, n_units):\n",
    "        initializer = chainer.initializers.HeNormal()\n",
    "        super(AIC_FC, self).__init__(\n",
    "            fc_in = L.Linear(None, n_units),\n",
    "            bn1 = L.BatchNormalization(n_units),\n",
    "            fc2 = L.Linear(None, n_units),\n",
    "            bn2 = L.BatchNormalization(n_units),\n",
    "            fc_out = L.Linear(None, 32*32*3)\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, t):\n",
    "        y = self.colorize(x)\n",
    "        loss = F.mean_squared_error(y, t)\n",
    "        chainer.reporter.report({\n",
    "            'loss': loss\n",
    "        })\n",
    "        return loss\n",
    "\n",
    "    def colorize(self, x, test=False):\n",
    "        h = F.elu(self.bn1(self.fc_in(x), test=test))\n",
    "        h = F.elu(self.bn2(self.fc2(h), test=test))\n",
    "        y = F.reshape(self.fc_out(h), (h.shape[0], 3, 32, 32))\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIC_DC(chainer.Chain):\n",
    "    def __init__(self, n_ch):\n",
    "        initializer = chainer.initializers.HeNormal()\n",
    "        super(AIC_DC, self).__init__(\n",
    "            cv_in = L.Convolution2D(1, n_ch//4, 4, 2, 1),\n",
    "            bn1 = L.BatchNormalization(n_ch//4),\n",
    "            cv1 = L.Convolution2D(n_ch//4, n_ch//2, 4, 2, 1),\n",
    "            bn2 = L.BatchNormalization(n_ch//2),\n",
    "            cv2 = L.Convolution2D(n_ch//2, n_ch, 4, 2, 1),\n",
    "            bn3 = L.BatchNormalization(n_ch),\n",
    "            cv3 = L.Convolution2D(n_ch, n_ch, 4, 2, 1),\n",
    "            bn4 = L.BatchNormalization(n_ch),\n",
    "            dc1 = L.Deconvolution2D(n_ch, n_ch, 4, 2, 1),\n",
    "            bn5 = L.BatchNormalization(n_ch),\n",
    "            dc2 = L.Deconvolution2D(n_ch, n_ch//2, 4, 2, 1),\n",
    "            bn6 = L.BatchNormalization(n_ch//2),\n",
    "            dc3 = L.Deconvolution2D(n_ch//2, n_ch//4, 4, 2, 1),\n",
    "            bn7 = L.BatchNormalization(n_ch//4),\n",
    "            dc_out = L.Deconvolution2D(n_ch//4, 3, 4, 2, 1, outsize=(32, 32))\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, t):\n",
    "        y = self.colorize(x)\n",
    "        loss = F.mean_squared_error(y, t)\n",
    "        chainer.reporter.report({\n",
    "            'loss': loss\n",
    "        })\n",
    "        return loss\n",
    "\n",
    "    def colorize(self, x, test=False):\n",
    "        # Convolution層に入力するため、ndimが4になるようにreshape\n",
    "        h = F.reshape(x, (x.shape[0], 1, 32, 32))\n",
    "        h = F.elu(self.bn1(self.cv_in(h), test=test))\n",
    "        h = F.elu(self.bn2(self.cv1(h), test=test))\n",
    "        h = F.elu(self.bn3(self.cv2(h), test=test))\n",
    "        h = F.elu(self.bn4(self.cv3(h), test=test))\n",
    "        h = F.elu(self.bn5(self.dc1(h), test=test))\n",
    "        h = F.elu(self.bn6(self.dc2(h), test=test))\n",
    "        h = F.elu(self.bn7(self.dc3(h), test=test))\n",
    "        y = self.dc_out(h)\n",
    "        return y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batchsize BATCHSIZE] [--epoch EPOCH]\n",
      "                             [--gpu GPU] [--resume RESUME] [--n_ch N_CH]\n",
      "                             [--n_units N_UNITS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\031674\\AppData\\Roaming\\jupyter\\runtime\\kernel-526e6a5b-2514-4e1a-931a-53a0ffa06650.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Automatic Image Colorization')\n",
    "    parser.add_argument('--batchsize', '-b', type=int, default=64,\n",
    "                        help='Number of images in each mini-batch')\n",
    "    parser.add_argument('--epoch', '-e', type=int, default=30,\n",
    "                        help='Number of sweeps over the dataset to train')\n",
    "    parser.add_argument('--gpu', '-g', type=int, default=0,\n",
    "                        help='GPU ID (negative value indicates CPU)')\n",
    "    parser.add_argument('--resume', '-r', default='',\n",
    "                        help='Resume the training from snapshot')\n",
    "    parser.add_argument('--n_ch', '-nc', type=int, default=1024,\n",
    "                        help='Number of channels')\n",
    "    parser.add_argument('--n_units', '-nu', type=int, default=0,\n",
    "                        help='Number of units')\n",
    "    args = parser.parse_args()\n",
    "    print('# GPU: {}'.format(args.gpu))\n",
    "    print('# Minibatch-size: {}'.format(args.batchsize))\n",
    "    print('# epoch: {}'.format(args.epoch))\n",
    "\n",
    "    if args.n_units > 0:\n",
    "        print('# n_units: {}\\n'.format(args.n_units))\n",
    "        model = AIC_FC(args.n_units)\n",
    "    else:\n",
    "        print('# n_ch: {}\\n'.format(args.n_ch))\n",
    "        model = AIC_DC(args.n_ch)\n",
    "    if args.gpu >= 0:\n",
    "        chainer.cuda.get_device().use()\n",
    "        model.to_gpu()\n",
    "\n",
    "    opt = chainer.optimizers.Adam()\n",
    "    opt.setup(model)\n",
    "\n",
    "    train, test = chainer.datasets.get_cifar100(withlabel=False)\n",
    "    test_img = (\n",
    "        0.298912*test[:64,0]\n",
    "        + 0.586611*test[:64,1]\n",
    "        + 0.114478*test[:64,2]\n",
    "    )\n",
    "    # 64枚の画像を8x8に並んだ一枚の画像として保存する\n",
    "    imsave(\n",
    "        'test.png',\n",
    "        test[:64]\n",
    "        .transpose(0, 2, 3, 1)\n",
    "        .reshape((8, 8, 32, 32, 3))\n",
    "        .transpose(1, 2, 0, 3, 4)\n",
    "        .reshape(8*32, 8*32, 3)\n",
    "    )\n",
    "    imsave(\n",
    "        'test_gray.png',\n",
    "        test_img\n",
    "        .reshape((8, 8, 32, 32))\n",
    "        .transpose(1, 2, 0, 3)\n",
    "        .reshape(8*32, 8*32)\n",
    "    )\n",
    "    if args.gpu >= 0:\n",
    "        test_img = chainer.cuda.to_gpu(test_img)\n",
    "\n",
    "\n",
    "    dataset = PreprocessedDataset(train)\n",
    "    iterator = chainer.iterators.MultiprocessIterator(dataset, args.batchsize)\n",
    "\n",
    "    updater = chainer.training.StandardUpdater(iterator, opt, device=args.gpu)\n",
    "    trainer = chainer.training.Trainer(updater, (args.epoch, 'epoch'))\n",
    "\n",
    "    trainer.extend(extensions.LogReport())\n",
    "    trainer.extend(extensions.PrintReport([\n",
    "        'epoch', 'loss', 'elapsed_time'\n",
    "    ]))\n",
    "    @chainer.training.make_extension(trigger=(10, 'epoch'))\n",
    "    def test_model(trainer):\n",
    "        # 値域を0~1にするため、clipped_reluを通す\n",
    "        colorized_img = chainer.cuda.to_cpu(F.clipped_relu(model.colorize(test_img, test=True), z=1.0).data)\n",
    "        imsave(\n",
    "            'test_colorized{}.png'.format(trainer.updater.epoch),\n",
    "            colorized_img\n",
    "            .transpose(0, 2, 3, 1)\n",
    "            .reshape((8, 8, 32, 32, 3))\n",
    "            .transpose(1, 2, 0, 3, 4)\n",
    "            .reshape(8*32, 8*32, 3)\n",
    "        )\n",
    "    trainer.extend(test_model)\n",
    "    trainer.extend(extensions.ProgressBar(update_interval=100))\n",
    "\n",
    "    trainer.run()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
